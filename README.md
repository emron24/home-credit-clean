Absolutely, Emran â€” hereâ€™s a restructured and polished version of your README thatâ€™s recruiter-ready, clearly organized, and aligned with your portfolio goals. Iâ€™ve grouped related sections, improved flow, and added clarity while preserving your original content.

---

# ğŸ¦ Home Credit Risk Analysis  
*A Portfolio Project for Data Analyst Roles*

---

## ğŸ“¢ Summary  
This project showcases my ability to:
- Clean and prepare messy real-world data  
- Perform exploratory analysis and visualization  
- Communicate insights clearly  
- Build and evaluate a baseline predictive model  

Itâ€™s designed to demonstrate core Data Analyst skills, with optional modeling to highlight growth potential toward Data Science.

---

## ğŸ“Œ Project Overview  
Using the **Home Credit Default Risk dataset** from Kaggle, this project explores factors that influence loan default. The focus is on:
- Data cleaning  
- Exploratory analysis  
- Insight generation  
- Baseline modeling (Logistic Regression)

---

## ğŸ““ Workflow & Notebooks  
The project is organized into step-by-step Jupyter notebooks:

| Notebook | Description |
|----------|-------------|
| [01 Data Loading](notebooks/01_data_loading.ipynb) | Load the dataset, inspect structure, and perform initial checks |
| [02 Feature Engineering](notebooks/02_feature_engineering.ipynb) | Handle missing values, encode categorical variables, and prepare features |
| [03 Model Preparation](notebooks/03_model_preparation.ipynb) | Scale features, split data, train a logistic regression model, and evaluate performance |

---

## ğŸ“Š Dataset Details  
- **Source**: [Home Credit Default Risk](https://www.kaggle.com/c/home-credit-default-risk)  
- **Target Variable**: `TARGET`  
  - `0` = Loan repaid  
  - `1` = Loan default  

---

## ğŸ” Exploratory Data Analysis (EDA)  
- Checked dataset structure and class balance  
- Visualized missing values (top 20 features)  
- Examined correlations with the target variable  

---

## ğŸ§¹ Data Cleaning  
- Dropped columns with >40% missing values  
- Imputed remaining missing values with placeholder (`-999`)  
- Encoded categorical features:  
  - Binary â†’ Label Encoding  
  - Multi-class â†’ One-Hot Encoding  

---

## âš™ï¸ Baseline Modeling  
- **Model**: Logistic Regression  
- **Scaling**: StandardScaler  
- **Metric**: ROC AUC  

**Results**:  
- ROC AUC â‰ˆ *0.63*  
- Indicates weak but non-random predictive power

---

## ğŸ“ˆ Visualizations  
- Target distribution  
- Missing values bar chart  
- Correlation heatmap  
- ROC curve  
- Feature importance (logistic regression coefficients)

- --
## ğŸ“Š Excel Dashboard

Alongside the Python notebooks, I built an interactive Excel dashboard to visualize loan repayment behavior.  
It includes five chart types with slicers for Occupation, Income Level, Marital Status, Gender, and Family Size.

### Dashboard Features
- Loan Status by Occupation Group (Clustered Column)
- Loan Status by Age Group (Line Chart)
- Income Level Distribution (Pie Chart)
- Loan Status by Family Size Group (Stacked Bar Chart)
- Income vs Credit Amount (Scatter Plot)

### Files
- `dashboards/loan_dashboard.xlsx` â€” Full interactive dashboard
- `dashboards/screenshots/` â€” PNGs of each chart

---

## ğŸ’¡ Key Insights  
- Dataset is **imbalanced** (fewer defaults than non-defaults)  
- Age (`DAYS_BIRTH`), income, and employment-related features are strong predictors  
- Logistic regression provides a baseline; tree-based models could improve performance

---

## ğŸš€ Next Steps  
- Try advanced models (Random Forest, XGBoost, LightGBM)  
- Apply hyperparameter tuning  
- Address class imbalance (SMOTE, class weights)  
- Engineer new features (ratios, interactions)

---

## ğŸ§‘â€ğŸ’» Skills Demonstrated  
- Data wrangling with **pandas**  
- EDA with **matplotlib** and **seaborn**  
- Feature engineering and encoding  
- Model training and evaluation with **scikit-learn**  
- Communicating insights with visuals and markdown

---

## ğŸ“ Project Structure

```text
project1-home/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_loading.ipynb
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â””â”€â”€ 03_model_preparation.ipynb
â”œâ”€â”€ sql_scripts/
â”‚   â””â”€â”€ *.sql
â”œâ”€â”€ screenshots/
â”‚   â””â”€â”€ *.png
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ¤– Assistant Handoff Pipeline â€” Stability Report

This section documents the successful implementation and debugging of a GitHub Actions workflow that automates notebook execution via repository dispatch.

### âœ… Status: Success

After a series of cascading failures, we performed a full diagnostic and implemented four core fixes. The latest run completed successfully with no warnings or errors.

#### 1. ğŸ§  Notebook Execution Fix (Critical)
- **Issue**: `NameError: name 'null' is not defined` due to raw JSON accidentally injected into a code cell.
- **Fix**: Rebuilt `notebooks/process-handoff.ipynb` programmatically to ensure clean structure and correct `parameters` tag for papermill.

#### 2. âš™ï¸ Workflow Configuration & Dependencies
- **Dependency Fix**: Added `papermill`, `ipykernel`, `jq`, and others to `requirements.txt` to ensure full environment setup.
- **Payload Fix**: Corrected shell parsing logic to extract `client_payload.handoff_id` and other nested fields properly.

#### 3. ğŸ§¹ Final Cleanup & Stability
- **Warning Fix**: Removed unused `token: input` from `git-auto-commit-action` to eliminate workflow warnings.
- **Git Conflict Resolution**: Resolved merge conflict caused by simultaneous status file commits and YAML updates.

### ğŸ“˜ Outcome
The assistant-handoff pipeline now runs cleanly end-to-end:
- Payload is parsed correctly
- Notebook executes with injected parameters
- Status file is committed to `main`

This demonstrates CI/CD automation, notebook orchestration, and robust debugging â€” valuable skills for data engineering and production-grade analytics.


## ğŸ™Œ Closing Note  
This project demonstrates my ability to transform a messy, real-world dataset into actionable insights through **data cleaning, EDA, visualization, and baseline modeling**. Itâ€™s part of my **Data Analyst portfolio**, with room to expand into advanced modeling for Data Science roles.
